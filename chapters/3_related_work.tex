\section{Related Work}
The literature review is divided into subsequent sections: 1) Position estimation using inertial sensors systems. 2) Sensor fusion in position and orientation estimation.

\subsection{Position estimation using inertial sensor systems}

Inertial sensor systems have been thoroughly researched with the purpose of delivering position estimation of a moving body. Inertial systems are autonomous and independent and do not rely on external information, such as radio signals or electromagnetic waves. Their navigation data have short-term high accuracy, great constancy, and elevated data update rate. They may be applied in an array of distinct positioning methods.

\subsubsection{Pedestrian Dead Reckoning}

Pedestrian dead reckoning (PDR) is among the most explored. PDR combines step detection, step length estimation, and orientation approximations to calculate the absolute position and heading of a walking user. PDR can operate with a single accelerometer, although superior precision and robustness are obtained with more sensors. An Inertial Measurement Unit (IMU) containing several accelerometers, gyroscopes, magnetometers, and even pressure sensors are commonly employed to recognize steps and orientation. Sensors might be body-mounted or shoe-mounted. Pedestrian navigation systems can aid the blind and visually impaired, locating and rescuing firefighters and other emergency workers, hiking, sports, and others. Pedestrian dead reckoning is commonly reviewed in the literature, being subject to studies in various settings.

Ladetto et al. \cite{ladetto2002step} applied PDR in urban and indoor areas seeking to assist blind people reaching unfamiliar locations along with aiming to facilitate emergency coordinators to track rescue workers. The study integrated a GPS receiver with a body mounted IMU applying pattern recognition to accelerometer signals, determining a user's step signature.

Stirling et al. \cite{stirling2003innovative} illustrate an experiment exploiting a shoe-mounted sensor prototype that calculates stride length with accelerometers and magnetometers. Their system measures angular acceleration by manipulating pairs of accelerometers as an alternative to gyroscopes.

Several other studies investigate the prospect of using inertial sensor systems to estimate the absolute position and heading of a walking user for multiple purposes \cite{steinhoff2010dead}\cite{weinberg2002using}\cite{kim2004step} \cite{collin2002mems}. The main drawback of PDR is its dependence on step prediction algorithms that must distinguish step direction and step lengths as the user changes pace.

\subsubsection{Strapdown Inertial Integration}

Strapdown inertial integration or strapdown inertial navigation system (SNIS) is another prevalent position method. With SNIS, sensors are usually tightly strapped or attached to the axes of the moving body's structure, lowering costs, and enhancing the system's reliability. This technique integrates accelerometer and gyroscope measurements to distinguish the variation of position and heading. The strapdown system demands a high-level measurement rate, on average, beyond 2000 Hz. Typically, higher measurement rates translate into more accurate integration readings of position and attitude. Strapdown systems are currently employed in commercial and military applications (airplanes, vessels, ROVs, projectiles) and are a topic of study among scholars.

Jameian et al. \cite{jameian2019robust}  introduced strapdown inertial navigation system to nautical environments, proposing a compensation method against disturbing forces affecting vessel motion caused by rough sea conditions. They aim to resolve attitude determination offset through self-alignment of SNIS by establishing vector observations. The implementation makes use of a quaternion estimator for attitude determination, significantly diminishing computational complexity.

An indoor strapdown inertial navigation with small foot-mounted and self-contained sensor systems was described by Bird et al. \cite{bird2011indoor}. Similar to pedestrian dead reckoning, SNIS also has applications in pedestrian navigation systems, although operating in an utterly distinct fashion. Unlike PDR, the strapdown navigation algorithm traces the entire movement of the foot in between steps. Any movement like walking, running, climbing up or down, moving backward or sideways, sliding, and even jumping can be tracked. This is possible because of a zero-velocity update algorithm (ZVU) which exploits the brief periods of zero velocity when the feet are stationary on the ground.

SNIS and PDR may also be used together, sharing the same inertial sensors. In this case, inertial navigation is incorporated within the multi-sensor integration architecture as the reference system and PDR as an aiding sensor.


With a focus on low-cost inertial motion sensors, Coyte et al. \cite{coyte2013displacement} applied PDR to sporting training and rehabilitation. They propose solutions to acceleration noise accumulation and gyroscope angle error problems. To improve the accuracy of displacement estimation with a low-grade IMU, they developed a zero-velocity update algorithm.

\subsection{Sensor fusion in position and orientation estimation }

Sensor fusion defines the blending of sensory information from two or more sources in a way that generates a more consistent and dependable understanding of the system. One that would otherwise not be possible when these sources were used individually \cite{hall1997introduction}. Fusing multiple inertial systems has raised significant interest and consideration in location and attitude performance improvement. Numerous methods arose in recent times that merge information from various systems such as inertial sensors, GNSS, radar, radio telescopes, signal of opportunity systems like Angle of Arrival (AOA), Time of Arrival (TOA), Received Signal Strength (RSS), and Signal to Noise Ratio (SNR). The combination of multiple sources can help reduce noise with two different sensor types. These separate systems are integrated by fusion filter algorithms which process each input and generate a more precise and reliable output \cite{elmenreich2002introduction}. A substantial sum of distinct solutions designed to assess the orientation of a rigid body regarding a reference frame exist in literature. Two main approaches aimed at sensor fusion exist, Kalman and complementary related filters. A comprehensive analysis of the literature will be conducted seeking to better understand the distinction between algorithms and how do they compare.

\subsubsection{Kalman filter}

Several research works have been conducted on Inertial Navigation Systems and Global Navigation Satellite System integration through data fusion, particularly using the Kalman filter. To overcome the shortcomings linked to the detached functioning of GNSS and INS, Wong et al. \cite{wong1988high} Qi et al. \cite{qi2002direct}, and Nassar et al. \cite{nassar2004improving} combined both systems so that their disadvantages were lessened or eradicated, complementing one another. While GNSS was comparatively more stable and consistent for long periods, INS had a more reliable and comprehensive short-term signal. Updating INS position and velocity with GNSS data corrected error expansion at the same time it delivered more precise estimates. The Kalman Filter attempted to adjust INS information based on the system error model whenever GNSS signals were interrupted or limited. These studies have demonstrated success in satisfying the accuracy requirements of low-precision applications. However, they could not deliver the high precision positioning some applications required. Hence, other studies attempted to achieve better performance of integrated INS/GNSS systems through the exploration of extended and adaptive Kalman filtering techniques. Mohamed and Schwarz \cite{mohamed1999adaptive} performed an analysis on INS/\acrshort{gnss} alternative integration through an adaptive Kalman filtering technique. Findings reveal that their adaptive Kalman filter outperformed by almost 50\% the conventional filter.

The use of data fusion in autonomous flying units such as Unmanned Aerial Vehicles (UAV) has recently gained particular concern due to the dissemination of consumer-grade quadcopters. In autonomous aerial settings, an accurate altitude reading is crucial to control the position of the flying system. However, such measurements are repeatedly corrupted with signal noise produced by the vehicle's motors. Het√©nyi et al. \cite{hetenyi2016sensor} applied a Kalman Filter to fuse the sonar and accelerometer signals, obtaining a considerably improved altitude estimate with minimal error. Similarly, Luo et al. \cite{luo2013uav} combined the UAV sensor system and received signal strength (RSS) in a Kalman filter solution. The study sought to increase position and altitude estimation as well as collision avoidance precision by approximating the distance between the receiver and the transmitter via the use of radiofrequency signals reducing the noise component.

Sharma et al. \cite{sharma2014sensor} present an experiment of Kalman filter-based sensor fusion for extrapolation of a robot's orientation and depth to obstacle by fusing the inputs from three infrared sensors and an inertial sensor system. The combination of multiple sensor inputs allowed the robot to operate in fault-tolerant applications and enhanced its obstacle avoidance decision making, localization, and orientation estimations.

\subsubsection{Complementary filter}

Madgwick et al. \cite{madgwick2020extended} outlined the formulation of an extended complementary filter algorithm and exhibited its applicability as a human motion monitoring wearable. Their design fused magnetic, angular rate, and gravity sensor data to remotely estimate limb orientation in stroke patients performing rehabilitation exercises. They analyzed performance under a range of circumstances and benchmarked alongside other frequently utilized sensor fusion algorithms. They claim an improved computational efficiency of over 30\% when compared with standard alternative algorithms.

A complementary filter designed for sensor fusion in quadrotor UAV employing a low-cost inertial measurement system was proposed by Noordin et al. \cite{noordin2018sensor}. The complementary filter filtered high-frequency signals associated with the gyroscope and low-frequency signals linked to the accelerometer. Findings demonstrate that the complementary filter technique overcame the over drift conundrum related to gyroscopes and was capable of computing attitude angles efficiently.
Euston et al. \cite{euston2008complementary} conducted an analogous study with a non-linear complementary filter for attitude estimation in a UAV utilizing a low-cost IMU. They broadened the experiment to incorporate a model of the longitudinal angle-of-attack corresponding to the UAV's airframe acceleration using airspeed data. As a result, they could estimate the acceleration of the UAV during continuous turns based on gyroscope and airspeed data. They accomplished attitude filtering performance of similar quality as an extended Kalman filter that fused GPS/INS at a far less computational cost.

\subsubsection{Sensor fusion algorithms comparison}

Some studies have conducted comparison experiments between the sensor fusion algorithms in distinct settings to assess their performance in that unique condition. Ludwig et al. \cite{ludwig2018comparison} compared Madgwick and Mahony in a foot-mounted experiment. Their findings revealed that Madgwick achieved better heading orientation than Mahony when compared to the ground truth. Nonetheless, the performance of Mahony was superior to Madgwick. The same authors tested on \cite{ludwig2018comparisonuav} quadcopters the Extended Kalman Filter, Madgwick, and Mahony filters. Results showed that Mahony delivered a more precise orientation estimation and faster execution time than Madgwick and EKF. Diaz et al. \cite{diaz2015evaluation} present a comparison among Madgwick and Mahony, a basic AHRS estimation algorithm, and the recent algorithm proposed by the authors. The study centered around comparing the performance of Madgwick, Mahony, Extended Kalman Filter, and their own sensor fusion algorithm, emphasizing the behavior under magnetic perturbations. Various examples of movement were analyzed, from carrying the sensor at separate places such as pocket, shoe, and hand. They concluded that their algorithm was slightly less influenced by magnetic perturbations than the others, but overall, the algorithms performed similarly.


% \begin{table}[h!]
%   \begin{center}
%     \caption{Literature categorization.}
%     \label{tab:table1}
%     \begin{tabular}{l|S|r}
%       \toprule % <-- Toprule here
%       \textbf{Value 1} & \textbf{Value 2} & \textbf{Value 3}\\
%       \midrule % <-- Midrule here
%       1 & 1110.1 & a\\
%       2 & 10.1 & b\\
%       3 & 23.113231 & c\\
%       \bottomrule % <-- Bottomrule here
%     \end{tabular}
%   \end{center}
% \end{table}

\subsection{Thesis Contribution}

With this study, we aim to design and build a low-cost, multipurpose Inertial Navigation System, intending to estimate the orientation and position of a moving object in three-dimensional space. This research additionally proposes introducing an experimental comparison among several established AHRS sensor fusion algorithms such as the Extended Kalman Filter, Madgwick, and Mahony algorithms. Furthermore, a quaternion-based gravity compensation filter will be presented, diminishing the influence of the gravity component on acceleration readings.

\section{Related Work}
The literature review is divided into subsequent sections: 1) Position estimation using inertial sensors systems. 2) Sensor fusion in position and orientation estimation.

\subsection{Position estimation using inertial sensor systems}

Inertial sensor systems have been thoroughly researched with the purpose of delivering position estimation of a moving body. Inertial systems are autonomous and independent and do not rely on external information, such as radio signals or electromagnetic waves. Their navigation data have short-term high accuracy, great constancy, and elevated data update rate. They may be applied in an array of distinct positioning methods.

\subsubsection{Pedestrian Dead Reckoning}

\acrfull{pdr} is among the most explored. \acrshort{pdr} combines step detection, step length estimation, and orientation approximations to calculate the absolute position and heading of a walking user. \acrshort{pdr} can operate with a single accelerometer, although superior precision and robustness are obtained with more sensors. An \acrshort{imu} containing several accelerometers, gyroscopes, magnetometers, and even pressure sensors are commonly employed to recognize steps and orientation. Sensors might be body-mounted or shoe-mounted. Pedestrian navigation systems can aid the blind and visually impaired, locating and rescuing firefighters and other emergency workers, hiking, sports, and others. \acrshort{pdr} is commonly reviewed in the literature, being subject to studies in various settings.

Ladetto et al. \cite{ladetto2002step} applied \acrshort{pdr} in urban and indoor areas seeking to assist blind people reaching unfamiliar locations along with aiming to facilitate emergency coordinators to track rescue workers. The study integrated a \acrshort{gps} receiver with a body mounted IMU applying pattern recognition to accelerometer signals, determining a user's step signature.

Stirling et al. \cite{stirling2003innovative} illustrate an experiment exploiting a shoe-mounted sensor prototype that calculates stride length with accelerometers and magnetometers. Their system measures angular acceleration by manipulating pairs of accelerometers as an alternative to gyroscopes.

Several other studies investigate the prospect of using inertial sensor systems to estimate the absolute position and heading of a walking user for multiple purposes \cite{steinhoff2010dead}\cite{weinberg2002using}\cite{kim2004step} \cite{collin2002mems}. The main drawback of \acrshort{pdr} is its dependence on step prediction algorithms that must distinguish step direction and step lengths as the user changes pace.

\subsubsection{Strapdown Inertial Integration}

Strapdown inertial integration or \acrfull{snis} is another prevalent position method. With SNIS, sensors are usually tightly strapped or attached to the axes of the moving body's structure, lowering costs, and enhancing the system's reliability. This technique integrates accelerometer and gyroscope measurements to distinguish the variation of position and heading. The strapdown system demands a high-level measurement rate, on average, beyond 2000 Hz. Typically, higher measurement rates translate into more accurate integration readings of position and attitude. Strapdown systems are currently employed in commercial and military applications (airplanes, vessels, \acrfull{rov}, projectiles) and are a topic of study among scholars.

Jameian et al. \cite{jameian2019robust}  introduced \acrshort{snis} to nautical environments, proposing a compensation method against disturbing forces affecting vessel motion caused by rough sea conditions. They aim to resolve attitude determination offset through self-alignment of SNIS by establishing vector observations. The implementation makes use of a quaternion estimator for attitude determination, significantly diminishing computational complexity.

An indoor strapdown inertial navigation with small foot-mounted and self-contained sensor systems was described by Bird et al. \cite{bird2011indoor}. Similar to \acrshort{pdr}, SNIS also has applications in pedestrian navigation systems, although operating in an utterly distinct fashion. Unlike \acrshort{pdr}, the strapdown navigation algorithm traces the entire movement of the foot in between steps. Any movement like walking, running, climbing up or down, moving backward or sideways, sliding, and even jumping can be tracked. This is possible because of a \acrfull{zvu} which exploits the brief periods of zero velocity when the feet are stationary on the ground.

SNIS and \acrshort{pdr} may also be used together, sharing the same inertial sensors. In this case, inertial navigation is incorporated within the multi-sensor integration architecture as the reference system and \acrshort{pdr} as an aiding sensor.


With a focus on low-cost inertial motion sensors, Coyte et al. \cite{coyte2013displacement} applied \acrshort{pdr} to sporting training and rehabilitation. They propose solutions to acceleration noise accumulation and gyroscope angle error problems. To improve the accuracy of displacement estimation with a low-grade IMU, they developed a \acrshort{zvu} algorithm.

\subsection{Sensor fusion in position and orientation estimation }

Sensor fusion defines the blending of sensory information from two or more sources in a way that generates a more consistent and dependable understanding of the system. One that would otherwise not be possible when these sources were used individually \cite{hall1997introduction}. Fusing multiple inertial systems has raised significant interest and consideration in location and attitude performance improvement. Numerous methods arose in recent times that merge information from various systems such as inertial sensors, \acrshort{gnss}, radar, radio telescopes, signal of opportunity systems like \acrfull{aoa}, \acrfull{toa}, \acrfull{rss}, and\acrfull{snr}. The combination of multiple sources can help reduce noise with two different sensor types. These separate systems are integrated by fusion filter algorithms which process each input and generate a more precise and reliable output \cite{elmenreich2002introduction}. A substantial sum of distinct solutions designed to assess the orientation of a rigid body regarding a reference frame exist in literature. Two main approaches aimed at sensor fusion exist, Kalman and complementary related filters. A comprehensive analysis of the literature will be conducted seeking to better understand the distinction between algorithms and how do they compare.

\subsubsection{Kalman filter}

Several research works have been conducted on \acrfull{ins} and \acrfull{gnss} integration through data fusion, particularly using the Kalman filter. To overcome the shortcomings linked to the detached functioning of \acrshort{gnss} and \acrshort{ins}, Wong et al. \cite{wong1988high} Qi et al. \cite{qi2002direct}, and Nassar et al. \cite{nassar2004improving} combined both systems so that their disadvantages were lessened or eradicated, complementing one another. While \acrshort{gnss} was comparatively more stable and consistent for long periods, \acrshort{ins} had a more reliable and comprehensive short-term signal. Updating \acrshort{ins} position and velocity with \acrshort{gnss} data corrected error expansion at the same time it delivered more precise estimates. The Kalman Filter attempted to adjust \acrshort{ins} information based on the system error model whenever \acrshort{gnss} signals were interrupted or limited. These studies have demonstrated success in satisfying the accuracy requirements of low-precision applications. However, they could not deliver the high precision positioning some applications required. Hence, other studies attempted to achieve better performance of integrated \acrshort{ins}/\acrshort{gnss} systems through the exploration of extended and adaptive Kalman filtering techniques. Mohamed and Schwarz \cite{mohamed1999adaptive} performed an analysis on \acrshort{ins}/\acrshort{gnss} alternative integration through an adaptive Kalman filtering technique. Findings reveal that their adaptive Kalman filter outperformed by almost 50\% the conventional filter.

The use of data fusion in autonomous flying units such as \acrshort{uav} has recently gained particular concern due to the dissemination of consumer-grade quadcopters. In autonomous aerial settings, an accurate altitude reading is crucial to control the position of the flying system. However, such measurements are repeatedly corrupted with signal noise produced by the vehicle's motors. Het√©nyi et al. \cite{hetenyi2016sensor} applied a Kalman Filter to fuse the sonar and accelerometer signals, obtaining a considerably improved altitude estimate with minimal error. Similarly, Luo et al. \cite{luo2013uav} combined the \acrshort{uav} sensor system and received signal strength (RSS) in a Kalman filter solution. The study sought to increase position and altitude estimation as well as collision avoidance precision by approximating the distance between the receiver and the transmitter via the use of radiofrequency signals reducing the noise component.

Sharma et al. \cite{sharma2014sensor} present an experiment of Kalman filter-based sensor fusion for extrapolation of a robot's orientation and depth to obstacle by fusing the inputs from three infrared sensors and an inertial sensor system. The combination of multiple sensor inputs allowed the robot to operate in fault-tolerant applications and enhanced its obstacle avoidance decision making, localization, and orientation estimations.

\subsubsection{Complementary filter}

Madgwick et al. \cite{madgwick2020extended} outlined the formulation of an \acrfull{ecf} algorithm and exhibited its applicability as a human motion monitoring wearable. Their design fused magnetic, angular rate, and gravity sensor data to remotely estimate limb orientation in stroke patients performing rehabilitation exercises. They analyzed performance under a range of circumstances and benchmarked alongside other frequently utilized sensor fusion algorithms. They claim an improved computational efficiency of over 30\% when compared with standard alternative algorithms.

A complementary filter designed for sensor fusion in quadrotor \acrshort{uav} employing a low-cost inertial measurement system was proposed by Noordin et al. \cite{noordin2018sensor}. The complementary filter filtered high-frequency signals associated with the gyroscope and low-frequency signals linked to the accelerometer. Findings demonstrate that the complementary filter technique overcame the over drift conundrum related to gyroscopes and was capable of computing attitude angles efficiently.
Euston et al. \cite{euston2008complementary} conducted an analogous study with a non-linear complementary filter for attitude estimation in a \acrshort{uav} utilizing a low-cost IMU. They broadened the experiment to incorporate a model of the longitudinal angle-of-attack corresponding to the \acrshort{uav}'s airframe acceleration using airspeed data. As a result, they could estimate the acceleration of the \acrshort{uav} during continuous turns based on gyroscope and airspeed data. They accomplished attitude filtering performance of similar quality as an \acrshort{ekf} that fused \acrshort{gps}/\acrshort{ins} at a far less computational cost.

\subsubsection{Sensor fusion algorithms comparison}

Some studies have conducted comparison experiments between the sensor fusion algorithms in distinct settings to assess their performance in that unique condition. Ludwig et al. \cite{ludwig2018comparison} compared Madgwick and Mahony in a foot-mounted experiment. Their findings revealed that Madgwick achieved better heading orientation than Mahony when compared to the ground truth. Nonetheless, the performance of Mahony was superior to Madgwick. The same authors tested on \cite{ludwig2018comparisonuav} quadcopters the \acrshort{ekf}, Madgwick, and Mahony filters. Results showed that Mahony delivered a more precise orientation estimation and faster execution time than Madgwick and \acrshort{ekf}. Diaz et al. \cite{diaz2015evaluation} present a comparison among Madgwick and Mahony, a basic \acrshort{ahrs} estimation algorithm, and the recent algorithm proposed by the authors. The study centered around comparing the performance of Madgwick, Mahony, \acrshort{ekf}, and their own sensor fusion algorithm, emphasizing the behavior under magnetic perturbations. Various examples of movement were analyzed, from carrying the sensor at separate places such as pocket, shoe, and hand. They concluded that their algorithm was slightly less influenced by magnetic perturbations than the others, but overall, the algorithms performed similarly.


% \begin{table}[h!]
%   \begin{center}
%     \caption{Literature categorization.}
%     \label{tab:table1}
%     \begin{tabular}{l|S|r}
%       \toprule % <-- Toprule here
%       \textbf{Value 1} & \textbf{Value 2} & \textbf{Value 3}\\
%       \midrule % <-- Midrule here
%       1 & 1110.1 & a\\
%       2 & 10.1 & b\\
%       3 & 23.113231 & c\\
%       \bottomrule % <-- Bottomrule here
%     \end{tabular}
%   \end{center}
% \end{table}

\subsection{Thesis Contribution}

With this study, we aim to design and build a low-cost, multipurpose \acrlong{ins}, intending to estimate the orientation and position of a moving object in three-dimensional space. This research additionally proposes introducing an experimental comparison among several established \acrshort{ahrs} sensor fusion algorithms such as the \acrshort{ekf}, Madgwick, and Mahony algorithms. Furthermore, a quaternion-based gravity compensation filter will be presented, diminishing the influence of the gravity component on acceleration readings.

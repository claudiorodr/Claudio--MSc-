\chapter*{Abstract}
\justify
With the surge of inexpensive, widely accessible, and precise \acrfull{mems} in recent years, inertial systems tracking movement have become ubiquitous nowadays. Contrary to \acrfull{gps}-based positioning,  \acrfull{ins} are intrinsically unaffected by signal jamming, blockage susceptibilities, and spoofing. Measurements from inertial sensors are also acquired at elevated sampling rates and may be numerically integrated to estimate position and orientation knowledge. These measurements are precise on a small-time scale but gradually accumulate errors over extended periods. Combining multiple inertial sensors in a method known as sensor fusion makes it possible to produce a more consistent and dependable understanding of the system, decreasing accumulative errors. Several sensor fusion algorithms occur in literature aimed at estimating the \acrfull{ahrs} of a rigid body with respect to a reference frame. This work describes the development and implementation of a low-cost, multipurpose \acrshort{ins} for position and orientation estimation. Additionally, it presents an experimental comparison of a series of sensor fusion solutions and benchmarking their performance on estimating the position of a moving object.

\keywords{ Sensor Fusion  \and \acrfull{ins} \and \acrfull{mems} \and \acrfull{imu} }